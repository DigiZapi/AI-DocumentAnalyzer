# ğŸ“š AI-Powered Document Analyzer

A sophisticated RAG (Retrieval-Augmented Generation) system that enables intelligent querying of PDF documents with support for text, images, and tables. Built with LangChain, ChromaDB, and Ollama.

![Python](https://img.shields.io/badge/python-3.10-blue.svg)

## âœ¨ Features

- **ğŸ” Intelligent Search**: Semantic search across text, images, and tables using vector embeddings
- **ğŸ¤– AI Agent**: Autonomous agent that decides which tools to use to answer your questions
- **ğŸ–¼ï¸ Image Analysis**: Automatic image extraction and caption generation using vision models
- **ğŸ“Š Table Extraction**: Extract and query tables from PDFs with structured data
- **ğŸ’¬ Conversation Memory**: Maintains context across multiple queries (Agent Mode)
- **ğŸŒ Web Interface**: User-friendly Streamlit interface for document interaction
- **ğŸ“ˆ Visual Content Filtering**: LLM-based relevance filtering for images

## ğŸ—ï¸ Architecture

### System Overview

### System Overview

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      PDF Documents            â”‚
                    â”‚    (pdf_files/*.pdf)          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PDF Processing Pipeline     â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚  ğŸ“„ Text Extraction           â”‚
                    â”‚     â””â”€â–º PDFPlumber            â”‚
                    â”‚  ğŸ–¼ï¸  Image Extraction          â”‚
                    â”‚     â””â”€â–º PyMuPDF (fitz)        â”‚
                    â”‚  ğŸ“Š Table Extraction          â”‚
                    â”‚     â””â”€â–º PDFPlumber + Pandas   â”‚
                    â”‚  ğŸ¤– Image Captioning          â”‚
                    â”‚     â””â”€â–º qwen3-vl:8b (Vision)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Embedding Generation        â”‚
                    â”‚   (qwen3-embedding:latest)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    ChromaDB Vector Store      â”‚
                    â”‚       (chroma_db/)            â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚  â€¢ Text chunks + embeddings   â”‚
                    â”‚  â€¢ Image captions + embeddingsâ”‚
                    â”‚  â€¢ Table data + embeddings    â”‚
                    â”‚  â€¢ Metadata & file references â”‚
                    â”‚  â€¢ Source document tracking   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Standard Search    â”‚                     â”‚     Agent Mode          â”‚
â”‚      (RAG Query)     â”‚                     â”‚  (LangChain ReAct)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Semantic search    â”‚                     â”‚ ğŸ§  Reasoning Engine     â”‚
â”‚ â€¢ Multi-type results â”‚                     â”‚ ğŸ”§ Tool Selection:      â”‚
â”‚ â€¢ Direct retrieval   â”‚                     â”‚   â€¢ standard_search     â”‚
â”‚ â€¢ Optional LLM       â”‚                     â”‚   â€¢ get_overview        â”‚
â”‚                      â”‚                     â”‚   â€¢ summarize_document  â”‚
â”‚                      â”‚                     â”‚ ğŸ’¬ Conversation Memory  â”‚
â”‚                      â”‚                     â”‚ ğŸ¯ Relevance Filtering  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                              â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Answer Generation  â”‚
                   â”‚   (gpt-oss:20b)     â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Streamlit Web UI   â”‚
                   â”‚  (localhost:8501)   â”‚
                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                   â”‚  â€¢ Query interface  â”‚
                   â”‚  â€¢ Result display   â”‚
                   â”‚  â€¢ Image gallery    â”‚
                   â”‚  â€¢ Table viewer     â”‚
                   â”‚  â€¢ PDF management   â”‚
                   â”‚  â€¢ Settings panel   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Query Flow

1. **User Query** â†’ Embedded using `qwen3-embedding:latest`
2. **Vector Search** â†’ ChromaDB finds similar content
3. **Content Retrieval** â†’ Text, image paths, and table data
4. **Context Building** â†’ Combined context for LLM
5. **Answer Generation** â†’ LLM generates response using context

See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for detailed architecture documentation.

## ğŸ› ï¸ Technologies Used

### Core Technologies
- **[LangChain](https://python.langchain.com/)**: LLM framework and agent orchestration
- **[ChromaDB](https://www.trychroma.com/)**: Vector database for semantic search
- **[Ollama](https://ollama.ai/)**: Local LLM inference engine
- **[Streamlit](https://streamlit.io/)**: Web interface framework
- **[PDFPlumber](https://github.com/jsvine/pdfplumber)**: PDF text and table extraction
- **[PyMuPDF](https://pymupdf.readthedocs.io/)**: PDF image extraction

### AI Models (Ollama)
- **qwen3-embedding:latest**: Text embeddings for vector search
- **qwen3-vl:8b**: Vision model for image captioning
- **gpt-oss:20b**: LLM for text generation and agent reasoning

### Data Processing
- **Pandas**: Table data manipulation
- **Pillow**: Image processing
- **NumPy**: Numerical operations

### Key Python Dependencies
- **LangChain** (v1.1.0): LLM framework and agent orchestration
- **LangGraph** (v1.0.4): Agent workflow management
- **ChromaDB** (v1.3.5): Vector database
- **Streamlit** (v1.51.0): Web interface
- **PDFPlumber** (v0.11.8): PDF text/table extraction
- **PyMuPDF** (v1.26.6): PDF image extraction
- **sentence-transformers** (v5.1.2): Embedding models


See `requirements.txt` for complete dependency list (187 packages).

## ğŸ“‹ Requirements

### System Requirements
- Python 3.10+ (tested with 3.10)
- 8GB RAM minimum (16GB recommended for larger models)
- Ollama installed and running locally
- GPU recommended but not required (CPU works but slower)

### Ollama Models
Install required models with:
```bash
ollama pull qwen3-embedding:latest
ollama pull qwen3-vl:8b
ollama pull gpt-oss:20b
```

Alternative smaller models (if memory is limited):
```bash
ollama pull llama3.2:1b  # Smaller LLM
ollama pull llava:7b     # Alternative vision model
```

## ğŸš€ Installation

### 1. Clone the Repository
```bash
git clone <repository-url>
cd DocumentAnalyzer
```

### 2. Create Virtual Environment
```bash
python -m venv .venv_da
source .venv_da/bin/activate  # On Windows: .venv_da\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Install and Start Ollama
Follow instructions at [ollama.ai](https://ollama.ai/) to install Ollama, then:
```bash
# Start Ollama service (if not auto-started)
ollama serve

# In another terminal, pull required models
ollama pull qwen3-embedding:latest
ollama pull qwen3-vl:8b
ollama pull gpt-oss:20b
```

### 5. Add Your PDF Files
Place your PDF documents in the `pdf_files/` directory:
```bash
mkdir -p pdf_files
cp your-documents.pdf pdf_files/
```

## ğŸ’» Usage

### Quick Start

#### 1. Build the Vector Database
Process your PDFs and create the vector database:
```bash
python src/app.py
# Select option 1: Create/Rebuild Vector Database
```

This will:
- Extract text, images, and tables from PDFs
- Generate image captions using vision model
- Create embeddings and store in ChromaDB
- Save images to `extracted_images/`

#### 2. Launch Web Interface
```bash
streamlit run src/app.py
# Or select option 2 from the menu
```

The web interface will open at `http://localhost:8501`


### Example Queries

```
"What are the installation instructions?"
"List all available documents"
"How do I configure the BIOS settings?"
"Summarize the file xyz"
```

### Web Interface Features

**Sidebar Settings:**
- Query mode selection (Standard/Agent)
- Result count adjustment
- LLM answer toggle
- PDF upload and management
- Conversation memory controls

**Main Display:**
- AI-generated answers
- Organized tabs for text, images, and tables
- Image gallery with captions
- Interactive table display
- Query history

## âš™ï¸ Configuration

Edit `config.py` to customize behavior:

```python
# Model Selection
EMBED_MODEL = "qwen3-embedding:latest"
VISION_MODEL = "qwen3-vl:8b"
AGENT_MODEL = "gpt-oss:20b"  # Unified model for all LLM operations
AGENT_TEMPERATURE = 0.1

# Performance Tuning
OLLAMA_NUM_CTX = 2048  # Context window size
OLLAMA_TIMEOUT = 240   # Request timeout (seconds)
TOP_K = 6              # Number of search results

# Image Processing
MIN_IMAGE_SIZE = 2000      # Skip small images (bytes)
MAX_IMAGE_SIZE = 5_000_000 # Skip large images (bytes)
CAPTION_RATE_LIMIT_DELAY = 1.5  # Delay between captions

# Agent Settings
ENABLE_IMAGE_FILTERING = True  # LLM-based image relevance filtering
MAX_RELEVANT_IMAGES = 3        # Max images after filtering
```

### Performance Tuning

If experiencing memory issues or crashes:

1. **Reduce context window**: `OLLAMA_NUM_CTX = 1024`
2. **Use smaller models**: `LLM_MODEL = "llama3.2:1b"`
3. **Increase delays**: `CAPTION_RATE_LIMIT_DELAY = 2.0`
4. **Skip more images**: `MIN_IMAGE_SIZE = 5000`

## ğŸ“ Project Structure

```
AI-DocumentAnalyzer/
â”‚
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ app.py                    # Main application entry point
â”‚   â”œâ”€â”€ streamlit_webinterface.py # Streamlit UI implementation
â”‚   â”œâ”€â”€ rag_backend.py            # RAG system and vector DB
â”‚   â”œâ”€â”€ agent.py                  # LangChain agent implementation
â”‚   â”œâ”€â”€ agent_tools.py            # Agent tool definitions
â”‚   â”œâ”€â”€ llm_singleton.py          # Singleton LLM instances (prevents memory leaks)
â”‚   â””â”€â”€ utility/                  # Utility modules
â”‚       â”œâ”€â”€ pdf_reader.py         # PDF extraction
â”‚       â””â”€â”€ caption_images.py     # Image captioning
â”‚
â”œâ”€â”€ pdf_files/                    # Input PDF documents (your PDFs go here)
â”œâ”€â”€ extracted_images/             # Extracted images from PDFs
â”œâ”€â”€ chroma_db/                    # ChromaDB vector database
â”œâ”€â”€ docs/                         # Additional documentation
â”‚   â””â”€â”€ ARCHITECTURE.md           # Detailed architecture docs
â”‚
â”œâ”€â”€ config.py                     # Configuration settings
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ .venv_da/                     # Virtual environment (not tracked)
```

## ğŸ”§ Advanced Usage

### Database Management

```bash
# Rebuild the vector database
python src/app.py  # Select option 1

# Launch web interface
streamlit run src/app.py  # Or select option 2 from menu
```

## ğŸ› Troubleshooting

### Common Issues

**Problem**: Ollama connection error
```bash
# Solution: Check if Ollama is running
ollama list
# If not running:
ollama serve
```

**Problem**: Out of memory errors
```python
# Solution: Reduce context window and timeout in config.py
OLLAMA_NUM_CTX = 1024  # or 512
OLLAMA_TIMEOUT = 300   # Increase timeout if needed
```

**Problem**: No results found
```bash
# Solution: Rebuild vector database
python src/app.py  # Select option 1
```

**Problem**: Agent not using correct tool
- The agent uses LangGraph's ReAct agent with tool calling
- Check system instructions in `src/agent.py` â†’ `_get_system_instructions()`
- Ensure your query clearly indicates what you want (search, overview, or summary)


# Reinstall dependencies if needed
pip install -r requirements.txt
```

## ğŸ“Œ Known Limitations

- **Large PDFs**: Very large PDFs (100+ pages) may take several minutes to process
- **Complex Tables**: Tables with merged cells or complex formatting may not extract perfectly
- **Image Quality**: Low-resolution images may produce poor captions
- **Memory Usage**: Processing many images simultaneously can consume significant RAM
- **Model Availability**: Requires Ollama models to be pre-downloaded locally

---

**Built with â¤ï¸ for intelligent document analysis**
